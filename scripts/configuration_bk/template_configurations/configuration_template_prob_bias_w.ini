[Node2Vec]
; note1 = parameters of biased random walks
p = 1
q = 0.05
num_walks = 10
num_steps = 5
vector_length = 128
batch_size = 1024
; note2 = parameters of the skip-gram model
learning_rate = 0.001
num_epochs = 50
num_negative_samples = 4
; note3 = to apply node2vec+ put True
extended = True
; note4 = weight system use equal, probabilistic, probabilistic_with_bias, or random
weight_system = probabilistic_with_bias

[Paths]
main_dir = .
hpo_filename = hp-2020-10-12.obo
hpo_path = ${main_dir}/data/${hpo_filename}
save_path = ${main_dir}/results/weights_${Node2Vec:weight_system}_extended_${Node2Vec:extended}
frequecy_filename = Table_S2.csv
frequecy_file = ${main_dir}/data/${frequecy_filename}

[DAG_Properties]
; note5 = to generate the dag for the first time, put False
load_saved_dag = False
dag_filename = ${Paths:save_path}/dag_freq_${Paths:frequecy_filename}_HPO_${Paths:hpo_filename}

[Saved_Files]
; note6 =  put True to load previously saved files for the weight_system, hpo_filename, and frequency_file combination, including hpo_graph, hpo_embeddings, dict_hpo, vocabulary_lookup, vocabulary.
load_saved = False
hpo_graph_filename = ${Paths:save_path}/hpo_graph
hpo_embeddings_filename = ${Paths:save_path}/hpo_embeddings
dict_hpo_filename = ${Paths:save_path}/dict_hpo
vocabulary_lookup_filename = ${Paths:save_path}/vocabulary_lookup
vocabulary_filename = ${Paths:save_path}/vocabulary

